{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import emcee\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HamiltonianMonteCarlo:\n",
    "    def __init__(self, U, grad_U, epsilon, L, M):\n",
    "        self.U = U  # Potential energy function\n",
    "        self.grad_U = grad_U  # Gradient of the potential energy function\n",
    "        self.epsilon = epsilon  # Step size\n",
    "        self.L = L  # Number of leapfrog steps\n",
    "        self.M = M  # Mass matrix\n",
    "        self.M_inv = jnp.linalg.inv(M)  # Inverse of the mass matrix\n",
    "        self.samples = None  # Placeholder for sampled points\n",
    "        self.time = None  # Placeholder for sampling time\n",
    "        self.acceptance_rate = None  # Placeholder for acceptance rate\n",
    "        self.mean = None  # Placeholder for mean of samples\n",
    "        self.covariance = None  # Placeholder for covariance of samples\n",
    "    \n",
    "    def leapfrog(self, q, p):\n",
    "        p = p - 0.5 * self.epsilon * self.grad_U(q)\n",
    "        for _ in range(self.L):\n",
    "            q = q + self.epsilon * jnp.dot(self.M_inv, p)\n",
    "            if _ < self.L - 1:\n",
    "                p = p - self.epsilon * self.grad_U(q)\n",
    "        p = p - 0.5 * self.epsilon * self.grad_U(q)\n",
    "        return q, p\n",
    "\n",
    "    def sample(self, key, num_samples):\n",
    "        start_time = time.time()\n",
    "        samples = []\n",
    "        accepted = 0\n",
    "\n",
    "        q = jnp.zeros(self.M.shape[0])  # Initial position\n",
    "        for _ in range(num_samples):\n",
    "            key, subkey = random.split(key)\n",
    "            p = random.normal(subkey, shape=q.shape) * jnp.sqrt(jnp.diag(self.M))\n",
    "\n",
    "            current_q = q\n",
    "            current_p = p\n",
    "\n",
    "            q, p = self.leapfrog(current_q, current_p)\n",
    "\n",
    "            current_U = self.U(current_q)\n",
    "            current_K = 0.5 * jnp.dot(current_p, jnp.dot(self.M_inv, current_p))\n",
    "            proposed_U = self.U(q)\n",
    "            proposed_K = 0.5 * jnp.dot(p, jnp.dot(self.M_inv, p))\n",
    "\n",
    "            acceptance_prob = jnp.exp(current_U - proposed_U + current_K - proposed_K)\n",
    "            if random.uniform(subkey) < acceptance_prob:\n",
    "                samples.append(q)\n",
    "                accepted += 1\n",
    "            else:\n",
    "                samples.append(current_q)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        self.samples = jnp.array(samples)\n",
    "        self.time = end_time - start_time\n",
    "        self.acceptance_rate = accepted / num_samples\n",
    "        self.mean = jnp.mean(self.samples, axis=0)\n",
    "        self.covariance = jnp.cov(self.samples, rowvar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_gaussian(x, mean, cov):\n",
    "    diff = x - mean\n",
    "    return 0.5 * jnp.dot(diff, jnp.linalg.solve(cov, diff))\n",
    "\n",
    "# The target distribution is proportional to exp(-multivariate_gaussian(x))\n",
    "def target_distribution_gauss_2d(x):\n",
    "    mean = jnp.array([1.0, -1.5])\n",
    "    cov = jnp.array([[4.0, 0.7], [0.7, 1.5]])  # Example covariance matrix\n",
    "    return multivariate_gaussian(x, mean, cov)\n",
    "\n",
    "grad_U = jit(grad(target_distribution_gauss_2d))\n",
    "epsilon = 0.1\n",
    "L = 10\n",
    "M = jnp.eye(2)  # Identity matrix for simplicity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sample sizes to test\n",
    "sample_sizes = [10000, 50000, 100000]\n",
    "results = {}\n",
    "key = random.PRNGKey(0)\n",
    "# Sampling procedure\n",
    "for size in sample_sizes:\n",
    "\n",
    "    key, subkey = random.split(key)\n",
    "    HM_gauss_2d = HamiltonianMonteCarlo(target_distribution_gauss_2d, grad_U, epsilon, L, M)\n",
    "    HM_gauss_2d.sample(key, size)\n",
    "    ar = HM_gauss_2d.acceptance_rate\n",
    "    ar = np.array([ar,ar])\n",
    "    samples_with_acceptance = np.vstack((ar,HM_gauss_2d.samples))\n",
    "    results[size] = samples_with_acceptance\n",
    "\n",
    "# Save the results\n",
    "\n",
    "for size in sample_sizes:\n",
    "    df = pd.DataFrame(results[size])\n",
    "    filename = f\"HMC_samples_2D_{size}.csv\"\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution_gauss_15d(x):\n",
    "    mean = jnp.ones(15)\n",
    "    cov = jnp.eye(15)* 0.5 + 0.5 \n",
    "    return multivariate_gaussian(x, mean, cov)\n",
    "\n",
    "grad_U = jit(grad(target_distribution_gauss_15d))\n",
    "epsilon = 0.1\n",
    "L = 5\n",
    "M = jnp.eye(15)  # Identity matrix for simplicity\n",
    "num_samples = 50000\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "HM_gauss_15d = HamiltonianMonteCarlo(target_distribution_gauss_15d, grad_U, epsilon, L, M)\n",
    "\n",
    "# Sample sizes to test\n",
    "sample_sizes = [10000, 50000, 100000]\n",
    "results = {}\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "# Sampling procedure\n",
    "for size in sample_sizes:\n",
    "    key, subkey = random.split(key)\n",
    "    HM_gauss_15d.sample(key, size)\n",
    "    samples_with_acceptance = np.insert(HM_gauss_15d.samples, 0, HM_gauss_15d.acceptance_rate, axis=0)\n",
    "    results[size] = samples_with_acceptance\n",
    "\n",
    "# Save the results\n",
    "\n",
    "for size in sample_sizes:\n",
    "    df = pd.DataFrame(results[size])\n",
    "    filename = f\"HMC_samples_15D_{size}.csv\"\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 2-dimensional Rosenbrock function\n",
    "def rosenbrock(x):\n",
    "    a = 1.0\n",
    "    b = 100.0\n",
    "    return (a - x[0])**2 + b * (x[1] - x[0]**2)**2\n",
    "\n",
    "# The target distribution is proportional to exp(-rosenbrock(x))\n",
    "def target_distribution_rosenbrock(x):\n",
    "    return rosenbrock(x)\n",
    "\n",
    "grad_U = jit(grad(target_distribution_rosenbrock))\n",
    "epsilon = 0.001  # Smaller step size for the Rosenbrock function\n",
    "L = 100  # More steps to better explore the steep regions\n",
    "M = jnp.eye(2)  # Identity mass matrix\n",
    "num_samples = 50000\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "HM_gauss_rosenbrock = HamiltonianMonteCarlo(target_distribution_rosenbrock, grad_U, epsilon, L, M)\n",
    "\n",
    "# Sample sizes to test\n",
    "sample_sizes = [10000, 50000, 100000]\n",
    "results = {}\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "# Sampling procedure\n",
    "for size in sample_sizes:\n",
    "    key, subkey = random.split(key)\n",
    "    HM_gauss_rosenbrock.sample(key, size)\n",
    "    samples_with_acceptance = np.insert(HM_gauss_rosenbrock.samples, 0, HM_gauss_rosenbrock.acceptance_rate, axis=0)\n",
    "    results[size] = samples_with_acceptance\n",
    "\n",
    "# Save the results\n",
    "\n",
    "for size in sample_sizes:\n",
    "    df = pd.DataFrame(results[size])\n",
    "    filename = f\"HMC_samples_RB_{size}.csv\"\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HM_gauss_rosenbrock.sample(key, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_rb = emcee.autocorr.integrated_time(HM_gauss_rosenbrock.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HM_gauss_rosenbrock.acceptance_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ac_rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(HM_gauss_rosenbrock.samples[:,0], HM_gauss_rosenbrock.samples[:,1], s=1,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
