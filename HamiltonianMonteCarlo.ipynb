{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HamiltonianMonteCarlo:\n",
    "    def __init__(self, U, grad_U, epsilon, L, M):\n",
    "        self.U = U  # Potential energy function\n",
    "        self.grad_U = grad_U  # Gradient of the potential energy function\n",
    "        self.epsilon = epsilon  # Step size\n",
    "        self.L = L  # Number of leapfrog steps\n",
    "        self.M = M  # Mass matrix\n",
    "        self.M_inv = jnp.linalg.inv(M)  # Inverse of the mass matrix\n",
    "        self.samples = None  # Placeholder for sampled points\n",
    "        self.time = None  # Placeholder for sampling time\n",
    "        self.acceptance_rate = None  # Placeholder for acceptance rate\n",
    "        self.mean = None  # Placeholder for mean of samples\n",
    "        self.covariance = None  # Placeholder for covariance of samples\n",
    "    \n",
    "    def leapfrog(self, q, p):\n",
    "        p = p - 0.5 * self.epsilon * self.grad_U(q)\n",
    "        for _ in range(self.L):\n",
    "            q = q + self.epsilon * jnp.dot(self.M_inv, p)\n",
    "            if _ < self.L - 1:\n",
    "                p = p - self.epsilon * self.grad_U(q)\n",
    "        p = p - 0.5 * self.epsilon * self.grad_U(q)\n",
    "        return q, p\n",
    "\n",
    "    def sample(self, key, num_samples):\n",
    "        start_time = time.time()\n",
    "        samples = []\n",
    "        accepted = 0\n",
    "\n",
    "        q = jnp.zeros(self.M.shape[0])  # Initial position\n",
    "        for _ in range(num_samples):\n",
    "            key, subkey = random.split(key)\n",
    "            p = random.normal(subkey, shape=q.shape) * jnp.sqrt(jnp.diag(self.M))\n",
    "\n",
    "            current_q = q\n",
    "            current_p = p\n",
    "\n",
    "            q, p = self.leapfrog(current_q, current_p)\n",
    "\n",
    "            current_U = self.U(current_q)\n",
    "            current_K = 0.5 * jnp.dot(current_p, jnp.dot(self.M_inv, current_p))\n",
    "            proposed_U = self.U(q)\n",
    "            proposed_K = 0.5 * jnp.dot(p, jnp.dot(self.M_inv, p))\n",
    "\n",
    "            acceptance_prob = jnp.exp(current_U - proposed_U + current_K - proposed_K)\n",
    "            if random.uniform(subkey) < acceptance_prob:\n",
    "                samples.append(q)\n",
    "                accepted += 1\n",
    "            else:\n",
    "                samples.append(current_q)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        self.samples = jnp.array(samples)\n",
    "        self.time = end_time - start_time\n",
    "        self.acceptance_rate = accepted / num_samples\n",
    "        self.mean = jnp.mean(self.samples, axis=0)\n",
    "        self.covariance = jnp.cov(self.samples, rowvar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
